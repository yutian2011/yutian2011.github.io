<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>内存管理 | 雨天 &#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="linux 32位内存管理;物理内存分配,回收;">
<meta property="og:type" content="article">
<meta property="og:title" content="内存管理">
<meta property="og:url" content="http://yoursite.com/2015/08/01/内存管理(LENOVO-PC--Lenovo--2015-08-30-18,16,50)/index.html">
<meta property="og:site_name" content="雨天 's blog">
<meta property="og:description" content="linux 32位内存管理;物理内存分配,回收;">
<meta property="og:image" content="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/97302897.jpg">
<meta property="og:image" content="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/99047889.jpg">
<meta property="og:image" content="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/43243549.jpg">
<meta property="og:image" content="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/31285578.jpg">
<meta property="og:image" content="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/10244405.jpg">
<meta property="og:image" content="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/54366497.jpg">
<meta property="og:image" content="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/31145012.jpg">
<meta property="og:image" content="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/95089228.jpg">
<meta property="og:image" content="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/62256952.jpg">
<meta property="og:image" content="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/94087550.jpg">
<meta property="og:updated_time" content="2015-08-30T10:16:46.889Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="内存管理">
<meta name="twitter:description" content="linux 32位内存管理;物理内存分配,回收;">
  
    <link rel="alternative" href="/atom.xml" title="雨天 &#39;s blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">雨天 &#39;s blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-内存管理(LENOVO-PC--Lenovo--2015-08-30-18,16,50)" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2015/08/01/内存管理(LENOVO-PC--Lenovo--2015-08-30-18,16,50)/" class="article-date">
  <time datetime="2015-08-01T09:23:41.000Z" itemprop="datePublished">2015-08-01</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/linux内核/">linux内核</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      内存管理
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>linux 32位内存管理;物理内存分配,回收;<br><a id="more"></a></p>
<h1 id="总述(个人总结)">总述(个人总结)</h1><p>1)物理内存分区:伙伴队列,页缓冲page_set<br>2)内存分配:底层(伙伴队列),二层(allow_pages,get_free_pages等),三层(slab),kmalloc.(个人理解)<br>3)高端地址分配<br>4)内存回收:调度时机,回收的内容:内容中又区分不同的方式的回收.</p>
<h1 id="分区">分区</h1><h2 id="物理地址空间的区和页,分配和释放物理页">物理地址空间的区和页,分配和释放物理页</h2><p>物理页在核心中有个数据结构,struct page.page结构是个数组.管理物理页.<br><code>struct page
{
     unsigned long flags;//什么页,权限,状态
     atomic_t _count;//引用计数器
     atomic_t _mapcount;//计数器
     unsigned long private;
     struct address_space *mapping;//地址空间,与文件映射相关
     pgoff_t index;//页偏移
     struct list_head lru;//换入换出有关
     void *virtual;//虚地址,页为高端物理地址内存时,映射到逻辑地址空间空间时,虚地址需要填入.
}</code><br>mmu寻址与硬件寻址不同,mmu寻址不到,但是硬件可以寻址到.</p>
<h2 id="区:">区:</h2><p>ZONE_DMA 0-16MB<br>ZONE_NORMAL 16MB~896MB<br>ZONE_HIGHMEM &gt;896MB<br>由于内核的虚拟和物理地址只差一个偏移量：物理地址 = 逻辑地址 – 0xC0000000。所以如果1G内核空间完全用来线性映射，显然物理内存也只能访问到1G区间，这显然是不合理的。HIGHMEM就是为了解决这个问题，专门开辟的一块不必线性映射，可以灵活定制映射，以便访问1G以上物理内存的区域。</p>
<p>ZONE_DMA:24位地址线,只能DMA寻址16mb.低地址空间前16mb.<br>ZONE_NORMAL:16-896<br>ZONE_HIGHMEN:&gt;896mb,896~1g,&gt;1g的.</p>
<p>1)这个划分时根据内核使用的虚空间划分的,或者称为逻辑地址空间.<br>2)实际映射物理地址时,不同区之间可能不连续,只是逻辑上是连续的.<br>3)前两个区,区内部是线性映射的.</p>
<p>每个区都有一个struct zone.<br>每个zone都有一个伙伴队列.伙伴算法解决了内存外部碎片问题.<br><img src="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/97302897.jpg" alt=""><br><img src="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/99047889.jpg" alt=""></p>
<p>目前的结构应该如下<br>`<br>struct zone {<br>     /<em> Fields commonly accessed by the page allocator </em>/</p>
<pre><code>/* zone watermarks, access <span class="keyword">with</span> *_wmark_pages(zone) macros */
unsigned long watermark[NR_WMARK];

/*
* When free pages are <span class="keyword">below</span> this point, additional steps are taken
* when reading <span class="keyword">the</span> <span class="type">number</span> <span class="keyword">of</span> free pages <span class="keyword">to</span> avoid per-cpu counter
* drift allowing watermarks <span class="keyword">to</span> be breached
*/
unsigned long percpu_drift_mark;

/*
* We don't know <span class="keyword">if</span> <span class="keyword">the</span> memory <span class="keyword">that</span> we're going <span class="keyword">to</span> allocate will be freeable
* <span class="keyword">or</span>/<span class="keyword">and</span> <span class="keyword">it</span> will be released eventually, so <span class="keyword">to</span> avoid totally wasting several
* GB <span class="keyword">of</span> ram we must reserve <span class="keyword">some</span> <span class="keyword">of</span> <span class="keyword">the</span> lower zone memory (otherwise we risk
* <span class="keyword">to</span> <span class="command">run</span> OOM <span class="function_start"><span class="keyword">on</span></span> <span class="keyword">the</span> lower zones despite there's tons <span class="keyword">of</span> freeable ram
* <span class="function_start"><span class="keyword">on</span></span> <span class="keyword">the</span> higher zones). This array <span class="keyword">is</span> recalculated <span class="keyword">at</span> runtime <span class="keyword">if</span> <span class="keyword">the</span>
* sysctl_lowmem_reserve_ratio sysctl changes.
*/
unsigned long          lowmem_reserve[MAX_NR_ZONES];
</code></pre><p>#ifdef CONFIG_NUMA<br>     int node;<br>     /*</p>
<pre><code>* zone reclaim becomes active <span class="keyword">if</span> more unmapped pages exist.
*/
<span class="keyword">unsigned</span> <span class="keyword">long</span>          min_unmapped_pages;
<span class="keyword">unsigned</span> <span class="keyword">long</span>          min_slab_pages;
<span class="keyword">struct</span> per_cpu_pageset     *pageset[NR_CPUS];
</code></pre><p>#else<br>     struct per_cpu_pageset     pageset[NR_CPUS];</p>
<p>#endif<br>     /*</p>
<pre><code>* <span class="built_in">free</span> areas of different sizes
*/
<span class="keyword">spinlock_t</span>          lock;
</code></pre><p>#ifdef CONFIG_MEMORY_HOTPLUG<br>     /<em> see spanned/present_pages for more description </em>/<br>     seqlock_t          span_seqlock;</p>
<p>#endif<br>     struct free_area     free_area[MAX_ORDER];</p>
<p>#ifndef CONFIG_SPARSEMEM<br>     /*</p>
<pre><code>* <span class="keyword">Flags</span> <span class="keyword">for</span> a pageblock_nr_pages <span class="keyword">block</span>. See pageblock-<span class="keyword">flags</span>.h.
* <span class="keyword">In</span> SPARSEMEM, this map <span class="keyword">is</span> stored <span class="keyword">in</span> struct mem_section
*/
unsigned long          *pageblock_flags;
</code></pre><p>#endif /<em> CONFIG_SPARSEMEM </em>/</p>
<pre><code>ZONE_PADDING(_pad1_)

<span class="comment">/* Fields commonly accessed by the page reclaim scanner */</span>
<span class="keyword">spinlock_t</span>          lru_lock;    
<span class="keyword">struct</span> zone_lru {
     <span class="keyword">struct</span> list_head <span class="built_in">list</span>;
} lru[NR_LRU_LISTS];

<span class="keyword">struct</span> zone_reclaim_stat reclaim_stat;

<span class="keyword">unsigned</span> <span class="keyword">long</span>          pages_scanned;        <span class="comment">/* since last reclaim */</span>
<span class="keyword">unsigned</span> <span class="keyword">long</span>          flags;             <span class="comment">/* zone flags, see below */</span>

<span class="comment">/* Zone statistics */</span>
<span class="keyword">atomic_long_t</span>          vm_stat[NR_VM_ZONE_STAT_ITEMS];

<span class="comment">/*
* prev_priority holds the scanning priority for this zone.  It is
* defined as the scanning priority at which we achieved our reclaim
* target at the previous try_to_free_pages() or balance_pgdat()
* invokation.
*
* We use prev_priority as a measure of how much stress page reclaim is
* under - it drives the swappiness decision: whether to unmap mapped
* pages.
*
* Access to both this field is quite racy even on uniprocessor.  But
* it is expected to average out OK.
*/</span>
<span class="keyword">int</span> prev_priority;

<span class="comment">/*
* The target ratio of ACTIVE_ANON to INACTIVE_ANON pages on
* this zone's LRU.  Maintained by the pageout code.
*/</span>
<span class="keyword">unsigned</span> <span class="keyword">int</span> inactive_ratio;


ZONE_PADDING(_pad2_)
<span class="comment">/* Rarely used or read-mostly fields */</span>

<span class="comment">/*
* wait_table          -- the array holding the hash table
* wait_table_hash_nr_entries     -- the size of the hash table array
* wait_table_bits     -- wait_table_size == (1 &lt;&lt; wait_table_bits)
*
* The purpose of all these is to keep track of the people
* waiting for a page to become available and make them
* runnable again when possible. The trouble is that this
* consumes a lot of space, especially when so few things
* wait on pages at a given time. So instead of using
* per-page waitqueues, we use a waitqueue hash table.
*
* The bucket discipline is to sleep on the same queue when
* colliding and wake all in that wait queue when removing.
* When something wakes, it must check to be sure its page is
* truly available, a la thundering herd. The cost of a
* collision is great, but given the expected load of the
* table, they should be so rare as to be outweighed by the
* benefits from the saved space.
*
* __wait_on_page_locked() and unlock_page() in mm/filemap.c, are the
* primary users of these fields, and in mm/page_alloc.c
* free_area_init_core() performs the initialization of them.
*/</span>
<span class="keyword">wait_queue_head_t</span>     * wait_table;
<span class="keyword">unsigned</span> <span class="keyword">long</span>          wait_table_hash_nr_entries;
<span class="keyword">unsigned</span> <span class="keyword">long</span>          wait_table_bits;

<span class="comment">/*
* Discontig memory support fields.
*/</span>
<span class="keyword">struct</span> pglist_data     *zone_pgdat;
<span class="comment">/* zone_start_pfn == zone_start_paddr &gt;&gt; PAGE_SHIFT */</span>
<span class="keyword">unsigned</span> <span class="keyword">long</span>          zone_start_pfn;

<span class="comment">/*
* zone_start_pfn, spanned_pages and present_pages are all
* protected by span_seqlock.  It is a seqlock because it has
* to be read outside of zone-&gt;lock, and it is done in the main
* allocator path.  But, it is written quite infrequently.
*
* The lock is declared along with zone-&gt;lock because it is
* frequently read in proximity to zone-&gt;lock.  It's good to
* give them a chance of being in the same cacheline.
*/</span>
<span class="keyword">unsigned</span> <span class="keyword">long</span>          spanned_pages;     <span class="comment">/* total size, including holes */</span>
<span class="keyword">unsigned</span> <span class="keyword">long</span>          present_pages;     <span class="comment">/* amount of memory (excluding holes) */</span>

<span class="comment">/*
* rarely used fields:
*/</span>
<span class="keyword">const</span> <span class="keyword">char</span>          *name;
</code></pre><p>} ____cacheline_internodealigned_in_smp;<br>`<br>unsigned long watermark[NR_WMARK];该区最小值,最低和最高的水位值.<br>free_area:伙伴算法的邻接表.4k为单元,4k为0,8k为1,16k为2,指数.<br>pageset:zone对所有cpu的一个页的缓存池,每个cpu分配一个元素,cpu先找对应缓存池中查找,如果没有才去伙伴队列中分配页.cpu释放页时,先释放到本cpu的pageset中,不直接放入伙伴队列中,当pageset页缓存大时,合并放入伙伴队列中去.smp中多cpu,竞争伙伴队列时,有压力,缓冲这个压力.<br>wait_table:wait块,进程分配的页满足不了,分配wait块,挂载,等待分配.</p>
<p>伙伴队列,伙伴算法:<br>定义：由一个母实体分成的两个各方面属性一致的两个子实体，这两个子实体就处于伙伴关系。在操作系统分配内存的过程中，一个内存块常常被分成两个大小相等的内存块，这两个大小相等的内存块就处于伙伴关系。它满足 3 个条件 ：1)两个块具有相同大小记为 2^K  2)它们的物理地址是连续的 3)从同一个大块中拆分出来<br>使用位图表示相邻伙伴的关系,管理伙伴.</p>
<p>4k,2的指数0 1 2 3,挂的4k页,8k页,16k页(各之间为离散的,16k页内是连续的)<br><img src="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/43243549.jpg" alt=""><br>4k页低12位为0,第十二位为0或1.如果4k页,没有,到8k,分为两个4k,8k没有,取出16k,分为两个8k,一个8k分为两个4k.<br>伙伴算法释放的思想<br>当释放2^order页大小内存时，查看它的伙伴是否空闲，如果空闲就将伙伴从该组链表中删除，并且将这两个空闲的伙伴内存区域合并成一个更高阶的空闲内存区域，依次这样操作下去。<br>伙伴算法内存分配的思想<br>    举例说明：假设请求分配4个页面，根据该算法先到第2(2^2=4)个组中寻找空闲块，如果该组没有空闲块就到第3(2^3=8)个组中寻找，假设在第3个组中找到空闲块，就把其中的4个页面分配出去，剩余的4个页面放到第2个组中。如果第三个组还是没有空闲块，就到第4(2^4=16)个组中寻找，如果在该组中找到空闲块，把其中的4个页面分配出去，剩余的12个页面被分成两部分，其中的8个页面放到第3个组，另外4个页面放到第2个组…依次类推。<br>每个zone都有自己的伙伴队列.<br>这里分配的内存从伙伴队列中分配的.</p>
<p>获取物理内存函数,最底层的一级<br><img src="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/31285578.jpg" alt=""><br>将给定的页转化为逻辑地址:void <em>page_address(struct page </em>page)<br>返回逻辑地址,肯定是DMA或者NORMAL,因为HIGNMEM中没有逻辑地址,&gt;896mb的,以后没有逻辑地址.<br>page–&gt;896mb的地址空间:<br>0~896MB逻辑地址在内存物理地址内存中线性映射的,一一对应.逻辑地址跟物理地址的计算完全的映射.<br>释放时,先放入pageset中,然后进行合并,伙伴算法.<br>cpu不能访问物理地址,需要转换为虚地址<br><img src="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/10244405.jpg" alt=""></p>
<p>kmalloc:获得以字节为单位的一块内核内存.<br>返回的内存块仍然为虚地址.<br>kmalloc() 函数本身是基于 slab 实现的。</p>
<p>参数中的flag:分配标志:行为修饰符和区修饰符<br><img src="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/54366497.jpg" alt=""><br><img src="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/31145012.jpg" alt=""><br><img src="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/95089228.jpg" alt=""><br>这里因为HIGHMEM分配的是没有虚拟地址的,只有物理地址,只能通过page的方式进行分配和返回.<br><img src="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/62256952.jpg" alt=""><br>GFP_USER:优先级最低.</p>
<p>kfree:释放kmalloc分配出来的内存块.</p>
<p>vmalloc:内存虚拟地址空间连续,不保证物理地址空间连续<br>kmalloc:虚拟地址空间连续,物理地址上也是连续的.<br>kmalloc通过页表项将物理上部连续的页转换为虚拟地址空间上连续的页.一般是用于NORMAL中.<br>vmalloc优先使用HIGHMEM内存。返回值为内核虚拟地址空间地址.</p>
<p>vmalloc分配的内存只是线性地址连续,物理地址不一定连续,不能直接用于DMA。<br>它通过分配非连续的物理内存块，再修改页表，把内存映射到逻辑地址空间的连续区域中。通过vmalloc获得的页必须一个一个地进行映射，效率不高，因此，只在不得已(一般是为了获得大块内存)时使用。vmalloc函数返回一个指针，指向逻辑上连续的一块内存区，其大小至少为size。在发生错误时，函数返回NULL。vmalloc可能睡眠，因此，不能从中断上下文中进行调用，也不能从其它不允许阻塞的情况下调用。要释放通过vmalloc所获得的内存，应使用vfree函数。<br>因此vmalloc理应优先使用廉价的Highmem内存，而把宝贵的低端内存，留给其他的内核操作。事实上也是如此，vmalloc实现函数的分配标志，指明了从Highmem分配.</p>
<h1 id="高端内存映射">高端内存映射</h1><p><img src="http://7xlglz.com1.z0.glb.clouddn.com/15-8-30/94087550.jpg" alt=""><br>永久映射:<br>在内核初始化页表管理机制时，专门用pkmap_page_table这个变量保存了PKMAP_BASE对应的页表项的地址，由pkmap_page_table来维护永久内核映射区的页表项的映射，页表项总数为LAST_PKMAP个，这里的永久并不是指调用kmap()建立的映射关系会一直持续下去无法解除，而是指在调用kunmap()解除映射之间这种映射会一直存在，这是相对于临时内核映射机制而言的。<br>       内核用一个pkmap_count数组来记录pkmap_page_table中每一个页表项的使用状态，其实就是为每个页表项分配一个计数器来记录相应的页表是否已经被用来映射。<br>kmap函数和kunmap函数<br>kmap函数允许睡眠,应该在进程上下文中使用,而且允许永久映射的数量有限.</p>
<p>临时映射:<br>临时内核映射和永久内核映射相比，其最大的特点就是不会阻塞请求映射页框的进程，因此临时内核映射请求可以发生在中断和可延迟函数中。kmap_atomic函数</p>
<p>非连续内存分配<br>非连续内存分配是指将物理地址不连续的页框映射到线性地址连续的线性地址空间，主要应用于大容量的内存分配。采用这种方式分配内存的主要优点是避免了外部碎片，而缺点是必须打乱内核页表，而且访问速度较连续分配的物理页框慢。</p>
<p>#　slab分配的原理和方法</p>
<p>分配和释放数据结构是内核普遍的操作.<br>slab分配器扮演了通用数据结构缓存层的角色.<br>slab机制是基于buddy算法的，前者是对后者的细化.<br>小内存的分配与回收<br>快速分配与对齐(着色)<br>着色区的大小使Slab中的每个对象的起始地址都按高速缓存中的”缓存行（cache line）”大小进行对齐（80386的一级高速缓存行大小为16字节，Pentium为32字节）。因为Slab是由1个页面或多个页面（最多为32）组成，因此，每个Slab都是从一个页面边界开始的，它自然按高速缓存的缓冲行对齐。但是，Slab中的对象大小不确定，设置着色区的目的就是将Slab中第一个对象的起始地址往后推到与缓冲行对齐的位置。因为一个缓冲区中有多个Slab，因此，应该把每个缓冲区中的各个Slab着色区的大小尽量安排成不同的大小，这样可以使得在不同的Slab中，处于同一相对位置的对象，让它们在高速缓存中的起始地址相互错开，这样就可以改善高速缓存的存取效率。</p>
<p>slab层设计<br>每个cache有三个slab队列:全满,全空,半空队列(有分配,有空闲)<br>cache管理三个slab队列,以及属性信息,管理的对象多大等.<br>每一个slab有struct slab<br>这里的着色,对齐,对齐的cpu中的cache线 cache line(128字节或64字节与架构有关),访问内存时.<br>一个slab管理一页或两页,对象数是固定的,事先计算出来的.<br>s_mem指向第一个对象的偏移.<br>针对不同对象做一个slab的cache对象.<br>专有的对象进行分配与回收.<br>file结构<br>inode<br>socket<br>tast_struct<br>page结构就不需要,多少个物理页就有多少个page结构.</p>
<p>slab层的管理是在每个高速缓存的基础上,,通过给整个内核一个简单的接口完成,通过结构可以创建和撤销新的高速缓存,并在高速缓存内分配和释放对象.<br>slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统。slab分配对象时，会使用最近释放的对象内存块，因此其驻留在CPU高速缓存的概率较高。<br>用于描述和管理cache的数据结构是struct kmem_cache<br>struct kmem_cache中定义了一个struct array_cache指针数组，数组的元素个数对应了系统的CPU数，和伙伴系统中的每CPU页框高速缓存类似，该结构用来描述每个CPU的本地高速缓存，它可以减少SMP系统中对于自旋锁的竞争。在每个array_cache的末端都用一个指针数组记录了slab中的空闲对象，分配对象时，采用LIFO方式，也就是将该数组中的最后一个索引对应的对象分配出去，以保证该对象还驻留在高速缓存中的可能性。实际上，每次分配内存都是直接与本地CPU高速缓存进行交互，只有当其空闲内存不足时，才会从kmem_list中的slab中引入一部分对象到本地高速缓存中，而kmem_list中的空闲对象也不足了，那么就要从伙伴系统中引入新的页来建立新的slab了，这一点也和伙伴系统的每CPU页框高速缓存很类似。</p>
<p>kmalloc分配小内存,基于cache,定制专用的cache,对象32/64/128字节等固定的cache,分配小内存时,从对应的cache的slab中.通过指针就知道内存大小,slab分配全部都是虚地址/逻辑地址,&lt;896mb内存中,逻辑地址里面找到分配,逻辑地址空间唯一,找到属于哪个cache中,知道有多大了.</p>
<p>创建slab:<br>cache指针cachep,标志,哪一块物理内存,内存的node,统一寻址的话一个node里面有三个zone.返回的地址共cache使用.while,所有页数设置标志,用于slab分配.</p>
<p>建立cache:<br>align:cache line对齐<br>分配的cache哪里分配出来的,kmem_cache_create哪里分配的cache.也是slab的分配器,最初手工创建的cache的分配器.从cache的cache的slab中分配出来的.<br>kmem_cache_create()的实际工作就是为新的缓存申请缓存描述符，array_cache描述符和kmem_list3描述符，并根据接收的参数对这三个结构中的变量进行相应的初始化。新创建的缓存是空的，不包含slab。<br>函数流程:</p>
<pre><code><span class="bullet">* </span>首先做参数有效性的检查
<span class="bullet">* </span>计算对齐值
<span class="bullet">* </span>分配一个缓存描述符
<span class="bullet">* </span>确定slab管理区(slab描述符+kmem<span class="emphasis">_bufctl_</span>t数组)的存储位置
<span class="bullet">* </span>调用calculate<span class="emphasis">_slab_</span>order()进行相关项的计算，包括分配给slab的页阶数，碎片大小，slab的对象数
<span class="bullet">* </span>计算着色偏移和可用的颜色数量
<span class="bullet">* </span>调用setup<span class="emphasis">_cpu_</span>cache()分配array<span class="emphasis">_cache描述符和kmem_</span>list3描述符并初始化相关变量
<span class="bullet">* </span>最后将缓存描述符插入cache<span class="emphasis">_chain中</span>
</code></pre><p>释放cache的条件</p>
<p>从一个缓存中分配对象总是遵循下面的原则：<br>1.本地高速缓存中是否有空闲对象，如果有的话则从其中获取对象，这时分配的对象是最“热”的；<br>2.如果本地高速缓存中没有对象，则从kmem_list3中的slab链表中寻找空闲对象并填充到本地高速缓存再分配；<br>3.如果所有的slab中都没有空闲对象了，那么就要创建新的slab,再分配 </p>
<p>创建好cache后,从slab中分配对象</p>
<p>要从一个命名的缓存中分配一个对象，可以使用 kmem_cache_alloc 函数。void kmem_cache_alloc( struct kmem_cache *cachep, gfp_t flags );<br>函数kmem_cache_alloc用于从特定的缓存获取对象，kmalloc用于从普通缓存中获取对象，它们的执行流程如下图所示.</p>
<p>zone数据结构中的三个阀值,高低最小.内存回收两方面的工作,遍历近程空间的物理页,淘汰出去,如果是cache中直接回收,text段,直接淘汰,如果是数据段与堆栈段中,检查是否为脏数据,脏数据写入磁盘兑换区,做标记,如果是干净的,则不向兑换区中写入;不向兑换区外换,核心里面的数据结构,slab空闲队列里页拿回来释放掉.<br>zone里面的pageset,有没有空闲页.</p>
<pre><code><span class="bullet">* </span>高端物理内存的映射
</code></pre><p>高端物理内存的使用:永久映射区,用户地址空间,临时映射区.<br>物理内存不够时,没有高端物理地址内存.<br>高端内存中的页不能永久的映射到内核地址空间上.</p>
<p>永久映射:要映射给定的page结构到内核地址空间.逻辑地址放入virtual字段中.将page结构放入相应的页表项中,并标记.<br>通过物理地址找到虚地址,标记去掉,virtual清0.</p>
<p>临时映射:用在不能睡眠的地方.<br>中断在用.驱动程序可用,用完释放.<br>用于DMA</p>
<p>cpu变量的分配与回收<br>分配数组,每个cpu对应一个元素.<br>分配cpu个数相同的数组,使用全局函数接口保证同步与互斥.</p>
<p>定义每个cpu的变量:使用宏命令.<br>这里是通过name</p>
<p>运行时分配cpu变量<br>这里是通过指针</p>
<p>cpu变量数组不对齐,cache线不对齐.访问时可能变量跨cache线边缘.</p>
<p>进程内存的分配与回收<br>创建进程fork()、程序载入execve()、映射文件mmap()、动态内存分配malloc()/brk()等进程相关操作都需要分配内存给进程。不过这时进程申请和获得的还不是实际内存，而是虚拟内存，准确的说是“内存区域”。进程对内存区域的分配最终都会归结到do_mmap（）函数上来（brk调用被单独以系统调用实现，不用do_mmap()），<br>内核使用do_mmap()函数创建一个新的线性地址区间。但是说该函数创建了一个新VMA并不非常准确，因为如果创建的地址区间和一个已经存在的地址区间相邻，并且它们具有相同的访问权限的话，那么两个区间将合并为一个。如果不能合并，那么就确实需要创建一个新的VMA了。但无论哪种情况， do_mmap()函数都会将一个地址区间加入到进程的地址空间中－－无论是扩展已存在的内存区域还是创建一个新的区域。<br>同样，释放一个内存区域应使用函数do_ummap()，它会销毁对应的内存区域。</p>
<p>上面已经看到进程所能直接操作的地址都为虚拟地址。当进程需要内存时，从内核获得的仅仅是虚拟的内存区域，而不是实际的物理地址，进程并没有获得物理内存（物理页面——页的概念请大家参考硬件基础一章），获得的仅仅是对一个新的线性地址区间的使用权。实际的物理内存只有当进程真的去访问新获取的虚拟地址时，才会由“请求页机制”产生“缺页”异常，从而进入分配实际页面的例程。<br>该异常是虚拟内存机制赖以存在的基本保证——它会告诉内核去真正为进程分配物理页，并建立对应的页表，这之后虚拟地址才实实在在地映射到了系统的物理内存上。（当然，如果页被换出到磁盘，也会产生缺页异常，不过这时不用再建立页表了）<br>这种请求页机制把页面的分配推迟到不能再推迟为止，并不急于把所有的事情都一次做完（这种思想有点像设计模式中的代理模式（proxy））。之所以能这么做是利用了内存访问的“局部性原理”，请求页带来的好处是节约了空闲内存，提高了系统的吞吐率。要想更清楚地了解请求页机制，可以看看《深入理解linux内核》一书。<br>这里我们需要说明在内存区域结构上的nopage操作。当访问的进程虚拟内存并未真正分配页面时，该操作便被调用来分配实际的物理页，并为该页建立页表项。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/08/01/内存管理(LENOVO-PC--Lenovo--2015-08-30-18,16,50)/" data-id="cidycpr34000j78o04rx52bns" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/08/01/内存管理(LENOVO-PC--Lenovo--2015-08-30-18,19,53)/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          内存管理
        
      </div>
    </a>
  
  
    <a href="/2015/08/01/内存管理(LENOVO-PC--Lenovo--2015-08-30-18,44,11)/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">内存管理</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/linux内核/">linux内核</a><span class="category-list-count">9</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux内核/">linux内核</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/进程/">进程</a><span class="tag-list-count">2</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/linux内核/" style="font-size: 10px;">linux内核</a> <a href="/tags/进程/" style="font-size: 10px;">进程</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">August 2015</a><span class="archive-list-count">13</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2015/08/30/调度/">调度</a>
          </li>
        
          <li>
            <a href="/2015/08/30/系统调用/">系统调用</a>
          </li>
        
          <li>
            <a href="/2015/08/30/虚拟文件系统/">虚拟文件系统</a>
          </li>
        
          <li>
            <a href="/2015/08/30/中断/">中断</a>
          </li>
        
          <li>
            <a href="/2015/08/01/进程/">进程</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 conanpzh<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

  </div>
</body>
</html>